defaults:
  - _self_
  - env@train_env: duckietown
  - env@eval_env: duckietown_eval
  - reward: linear_mlp
  - override hydra/launcher: submitit_local

expert_dir: '/workspaces/duckietown-irl/data/${train_env.map_name}'
# task settings
discount: 0.98
# train settings
num_seed_frames: 12000
num_train_frames: 4000000
# eval
eval_every_episodes: 5
update_reward_every_episodes: 5
num_eval_episodes: 10
# snapshot
save_snapshot: true
save_snapshot_every_episodes: 50
snapshot_buffer: False
# replay buffer
replay_buffer_size: 500000
replay_buffer_num_workers: 1
nstep: 3
batch_size: 128
# misc
seed: 1
device: cuda
use_tb: True
save_video: true
save_train_video: false
record_video_every_episodes: 50
# experiment
# agent
use_joint_encoder: True
warmstart_reward_steps: 500000

agent:
  _target_: src.agents.drqv2.DrQV2Agent
  obs_shape: ??? # to be specified later
  action_shape: ??? # to be specified later
  device: ${device}
  critic_lr: 0.0001
  actor_lr: 0.000000005
  encoder_lr: 0.001
  critic_target_tau: 0.01
  update_every_steps: 2
  is_constraint: ${reward.is_constraint}
  use_tb: ${use_tb}
  num_expl_steps: 2000
  hidden_dim: 1024
  feature_dim: 50
  stddev_schedule: linear(0.05,0.01,5000000) #${stddev_schedule}
  stddev_clip: 0.02

hydra:
  run:
    dir: ../exp_local/${now:%Y.%m.%d}/${now:%H%M%S}_${hydra.job.override_dirname}
  sweep:
    dir: ../exp/${now:%Y.%m.%d}/${now:%H%M}_${agent_cfg.experiment}
    subdir: ${hydra.job.num}
  launcher:
    timeout_min: 4300
    cpus_per_task: 10
    gpus_per_node: 1
    tasks_per_node: 1
    mem_gb: 160
    nodes: 1
    submitit_folder: ../exp/${now:%Y.%m.%d}/${now:%H%M%S}_${agent_cfg.experiment}/.slurm
